<!DOCTYPE html>
<html>

<head>
    <title>socket</title>
    <meta charset="UTF-8">
    <style>
        #g {
            border: 1px solid black;
            height: 800px;
            width: 800px;
        }

    </style>
    <script src="https://unpkg.com/deeplearn"></script>
</head>

<body>
</body>
<script>
    'use strict'
    //搭建基础环境
    var dl = deeplearn;
    var math = new dl.NDArrayMathCPU();
    //建立图
    var g= new dl.Graph();
    
    var data = g.placeholder('data',[1,2]);
    var label = g.placeholder('label',[1,1]);
    
    //一层隐藏层
    var w1 = g.variable('w1',dl.Array2D.randNormal([2,3]));
    var b1 = g.variable('b1',dl.Array2D.randNormal([1,3]));
    
    var w2 = g.variable('w2',dl.Array2D.randNormal([3,1]));
    var b2 = g.variable('b2',dl.Array2D.randNormal([1,1]));
    
    /*
    //二层隐藏层
    var w1 = g.variable('w1',dl.Array2D.randNormal([2,3]));
    var b1 = g.variable('b1',dl.Array2D.randNormal([1,3]));
    
    var w2 = g.variable('w2',dl.Array2D.randNormal([3,2]));
    var b2 = g.variable('b2',dl.Array2D.randNormal([1,2]));
    
    var w3 = g.variable('w3',dl.Array2D.randNormal([2,1]));
    var b3 = g.variable('b3',dl.Array2D.randNormal([1,1]));
    */
    //一层隐藏层的训练
    var m1h1 = g.sigmoid( g.add( g.matmul( data , w1), b1 ) );
    
    var m1o = g.sigmoid( g.add( g.matmul( m1h1 , w2), b2 ) );
    //var m1o = g.sigmoid( g.add( g.matmul( m1h2 , w3), b3 ) );
    var costTensor = g.meanSquaredCost(m1o,label);
    

    /*留档
    const inputShape = [3];
    const inputTensor = g.placeholder('input', inputShape);

    const labelShape = [1];
    const labelTensor = g.placeholder('label', labelShape);

    // Variables are containers that hold a value that can be updated from
    // training.
    // Here we initialize the multiplier variable randomly.
    const multiplier = g.variable('multiplier', dl.Array2D.rand([2, 3],Math.random));//这里有问题
    const w2 = g.variable('w2',dl.Array2D.randNormal([1,2]));

    // Top level graph methods take Tensors and return Tensors.
    const outputTensor1 = g.sigmoid ( g.matmul( multiplier,inputTensor) ); // 3*1
    
    console.log(outputTensor1.shape);
    
    const outputTensor = g.sigmoid( g.matmul( w2 , outputTensor1) );
    
    console.log(outputTensor.shape);
    const costTensor = g.meanSquaredCost(outputTensor, labelTensor);

    // Tensors, like NDArrays, have a shape attribute.
    console.log(outputTensor.shape);
    */






    const learningRate = 0.001;
    const optimizer = new dl.AdamOptimizer(learningRate,0.9,0.999);
    const batchSize = 4;

    const session = new dl.Session(g, math);
    //const optimizer = new dl.SGDOptimizer(learningRate);
    

    const inputs = [
        dl.Array2D.new([1,2],[1,1]),
        dl.Array2D.new([1,2],[1,0]),
        dl.Array2D.new([1,2],[0,1]),
        dl.Array2D.new([1,2],[0,0])
    ];

    const labels = [
        dl.Array2D.new([1,1],[0]),
        dl.Array2D.new([1,1],[1]),
        dl.Array2D.new([1,1],[1]),
        dl.Array2D.new([1,1],[0])
    ];

    // Shuffles inputs and labels and keeps them mutually in sync.
    const shuffledInputProviderBuilder =
        new dl.InCPUMemoryShuffledInputProviderBuilder([inputs, labels]);
    
    const inputProvider =
    shuffledInputProviderBuilder.getInputProviders()[0];
    
    const labelProvider = shuffledInputProviderBuilder.getInputProviders()[1];

    // Maps tensors to InputProviders.
    const feedEntries = [{
            tensor: data,
            data: inputProvider
        },
        {
            tensor: label,
            data: labelProvider
        }
    ];

    const NUM_BATCHES = 20001;
    for (let i = 0; i < NUM_BATCHES; i++) {
        // Train takes a cost tensor to minimize. Trains one batch. Returns the
        // average cost as a Scalar.
        var cost = session.train(
            costTensor, feedEntries, batchSize, optimizer, dl.CostReduction.MEAN);
        if(i % 5000 == 0){
            document.write('last average cost (' + i + '): ' + cost.get()+"<br>");
        }
        
    }

    
    
    //math.track(dl.Array2D.new([1,2],[1,1]));
    //math.track(dl.Array2D.new([1,2],[1,0]));
    //math.track(dl.Array2D.new([1,2],[0,1]));
    const testInput = math.track(dl.Array2D.new([1,2],[0,0]));
    

// session.eval can take NDArrays as input data.
const testFeedEntries = [
  {tensor: data, data: testInput}
];

const testOutput = session.eval(m1o, testFeedEntries);

document.write('---inference output---'+"<br>");
document.write('shape: ' + testOutput.shape+"<br>");
document.write('value: ' + testOutput.getValues()+"<br>");
    
    
    /*
    var w11 = session.activationArrayMap.dict[2];
    var w22 = session.activationArrayMap.dict[3];
    var data = [dl.Array2D.new([3,1],[1,1,1]),dl.Array2D.new([3,1],[0,1,1]),dl.Array2D.new([3,1],[1,0,1]),dl.Array2D.new([3,1],[0,0,1])];
    for(var x in data){
        var d = data[x];
        var h = math.sigmoid( math.matMul( w11,d  ));
        var r = math.sigmoid( math.matMul(w22,h));
        console.log(r.getValues());
    }*/
</script>

</html>
